{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/500], Loss: 1.8914\n",
      "Epoch [200/500], Loss: 1.8637\n",
      "Epoch [300/500], Loss: 1.8379\n",
      "Epoch [400/500], Loss: 1.8138\n",
      "Epoch [500/500], Loss: 1.7912\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "input_dim = 16  \n",
    "hidden_size = 200\n",
    "num_classes = 7 \n",
    "\n",
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.RELU = nn.LeakyReLU()\n",
    "        self.lin2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.lin1(x)\n",
    "        x = self.RELU(x)\n",
    "        x = self.lin2(x)\n",
    "        return x \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>58238</td>\n",
       "      <td>971.303</td>\n",
       "      <td>397.202654</td>\n",
       "      <td>186.945510</td>\n",
       "      <td>2.124697</td>\n",
       "      <td>0.882317</td>\n",
       "      <td>58977</td>\n",
       "      <td>272.306674</td>\n",
       "      <td>0.604756</td>\n",
       "      <td>0.987470</td>\n",
       "      <td>0.775723</td>\n",
       "      <td>0.685561</td>\n",
       "      <td>0.006820</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.469994</td>\n",
       "      <td>0.998595</td>\n",
       "      <td>HOROZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>44515</td>\n",
       "      <td>757.601</td>\n",
       "      <td>265.590470</td>\n",
       "      <td>213.967453</td>\n",
       "      <td>1.241266</td>\n",
       "      <td>0.592420</td>\n",
       "      <td>44780</td>\n",
       "      <td>238.071960</td>\n",
       "      <td>0.771745</td>\n",
       "      <td>0.994082</td>\n",
       "      <td>0.974620</td>\n",
       "      <td>0.896387</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.803510</td>\n",
       "      <td>0.997370</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>31662</td>\n",
       "      <td>653.783</td>\n",
       "      <td>239.902428</td>\n",
       "      <td>168.421505</td>\n",
       "      <td>1.424417</td>\n",
       "      <td>0.712136</td>\n",
       "      <td>32034</td>\n",
       "      <td>200.781748</td>\n",
       "      <td>0.801407</td>\n",
       "      <td>0.988387</td>\n",
       "      <td>0.930853</td>\n",
       "      <td>0.836931</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.700453</td>\n",
       "      <td>0.997737</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38778</td>\n",
       "      <td>734.020</td>\n",
       "      <td>268.446281</td>\n",
       "      <td>184.061923</td>\n",
       "      <td>1.458456</td>\n",
       "      <td>0.727925</td>\n",
       "      <td>39208</td>\n",
       "      <td>222.201897</td>\n",
       "      <td>0.766137</td>\n",
       "      <td>0.989033</td>\n",
       "      <td>0.904439</td>\n",
       "      <td>0.827733</td>\n",
       "      <td>0.006923</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.685142</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42530</td>\n",
       "      <td>775.403</td>\n",
       "      <td>281.212824</td>\n",
       "      <td>193.236878</td>\n",
       "      <td>1.455275</td>\n",
       "      <td>0.726511</td>\n",
       "      <td>43028</td>\n",
       "      <td>232.703412</td>\n",
       "      <td>0.729816</td>\n",
       "      <td>0.988426</td>\n",
       "      <td>0.888895</td>\n",
       "      <td>0.827499</td>\n",
       "      <td>0.006612</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.684755</td>\n",
       "      <td>0.996507</td>\n",
       "      <td>SIRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10829</th>\n",
       "      <td>10829</td>\n",
       "      <td>37777</td>\n",
       "      <td>716.007</td>\n",
       "      <td>250.174662</td>\n",
       "      <td>192.704033</td>\n",
       "      <td>1.298233</td>\n",
       "      <td>0.637708</td>\n",
       "      <td>38174</td>\n",
       "      <td>219.315230</td>\n",
       "      <td>0.770519</td>\n",
       "      <td>0.989600</td>\n",
       "      <td>0.925983</td>\n",
       "      <td>0.876648</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.768513</td>\n",
       "      <td>0.997708</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10830</th>\n",
       "      <td>10830</td>\n",
       "      <td>32187</td>\n",
       "      <td>667.621</td>\n",
       "      <td>247.778775</td>\n",
       "      <td>165.786862</td>\n",
       "      <td>1.494562</td>\n",
       "      <td>0.743179</td>\n",
       "      <td>32582</td>\n",
       "      <td>202.439525</td>\n",
       "      <td>0.731805</td>\n",
       "      <td>0.987877</td>\n",
       "      <td>0.907466</td>\n",
       "      <td>0.817017</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.667517</td>\n",
       "      <td>0.997646</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10831</th>\n",
       "      <td>10831</td>\n",
       "      <td>81837</td>\n",
       "      <td>1095.937</td>\n",
       "      <td>433.838186</td>\n",
       "      <td>241.527026</td>\n",
       "      <td>1.796230</td>\n",
       "      <td>0.830699</td>\n",
       "      <td>82554</td>\n",
       "      <td>322.797312</td>\n",
       "      <td>0.771996</td>\n",
       "      <td>0.991315</td>\n",
       "      <td>0.856226</td>\n",
       "      <td>0.744050</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.553610</td>\n",
       "      <td>0.994412</td>\n",
       "      <td>CALI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10832</th>\n",
       "      <td>10832</td>\n",
       "      <td>48212</td>\n",
       "      <td>826.362</td>\n",
       "      <td>309.639462</td>\n",
       "      <td>199.285811</td>\n",
       "      <td>1.553746</td>\n",
       "      <td>0.765357</td>\n",
       "      <td>48777</td>\n",
       "      <td>247.760822</td>\n",
       "      <td>0.677002</td>\n",
       "      <td>0.988417</td>\n",
       "      <td>0.887206</td>\n",
       "      <td>0.800159</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.640255</td>\n",
       "      <td>0.994793</td>\n",
       "      <td>SIRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10833</th>\n",
       "      <td>10833</td>\n",
       "      <td>28026</td>\n",
       "      <td>610.943</td>\n",
       "      <td>215.446569</td>\n",
       "      <td>165.740377</td>\n",
       "      <td>1.299904</td>\n",
       "      <td>0.638903</td>\n",
       "      <td>28302</td>\n",
       "      <td>188.901592</td>\n",
       "      <td>0.776688</td>\n",
       "      <td>0.990248</td>\n",
       "      <td>0.943560</td>\n",
       "      <td>0.876791</td>\n",
       "      <td>0.007687</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.768762</td>\n",
       "      <td>0.999317</td>\n",
       "      <td>DERMASON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10834 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID   Area  Perimeter  MajorAxisLength  MinorAxisLength  \\\n",
       "0          0  58238    971.303       397.202654       186.945510   \n",
       "1          1  44515    757.601       265.590470       213.967453   \n",
       "2          2  31662    653.783       239.902428       168.421505   \n",
       "3          3  38778    734.020       268.446281       184.061923   \n",
       "4          4  42530    775.403       281.212824       193.236878   \n",
       "...      ...    ...        ...              ...              ...   \n",
       "10829  10829  37777    716.007       250.174662       192.704033   \n",
       "10830  10830  32187    667.621       247.778775       165.786862   \n",
       "10831  10831  81837   1095.937       433.838186       241.527026   \n",
       "10832  10832  48212    826.362       309.639462       199.285811   \n",
       "10833  10833  28026    610.943       215.446569       165.740377   \n",
       "\n",
       "       AspectRation  Eccentricity  ConvexArea  EquivDiameter    Extent  \\\n",
       "0          2.124697      0.882317       58977     272.306674  0.604756   \n",
       "1          1.241266      0.592420       44780     238.071960  0.771745   \n",
       "2          1.424417      0.712136       32034     200.781748  0.801407   \n",
       "3          1.458456      0.727925       39208     222.201897  0.766137   \n",
       "4          1.455275      0.726511       43028     232.703412  0.729816   \n",
       "...             ...           ...         ...            ...       ...   \n",
       "10829      1.298233      0.637708       38174     219.315230  0.770519   \n",
       "10830      1.494562      0.743179       32582     202.439525  0.731805   \n",
       "10831      1.796230      0.830699       82554     322.797312  0.771996   \n",
       "10832      1.553746      0.765357       48777     247.760822  0.677002   \n",
       "10833      1.299904      0.638903       28302     188.901592  0.776688   \n",
       "\n",
       "       Solidity  roundness  Compactness  ShapeFactor1  ShapeFactor2  \\\n",
       "0      0.987470   0.775723     0.685561      0.006820      0.000929   \n",
       "1      0.994082   0.974620     0.896387      0.005966      0.002376   \n",
       "2      0.988387   0.930853     0.836931      0.007577      0.002293   \n",
       "3      0.989033   0.904439     0.827733      0.006923      0.002005   \n",
       "4      0.988426   0.888895     0.827499      0.006612      0.001912   \n",
       "...         ...        ...          ...           ...           ...   \n",
       "10829  0.989600   0.925983     0.876648      0.006622      0.002413   \n",
       "10830  0.987877   0.907466     0.817017      0.007698      0.002116   \n",
       "10831  0.991315   0.856226     0.744050      0.005301      0.001002   \n",
       "10832  0.988417   0.887206     0.800159      0.006422      0.001624   \n",
       "10833  0.990248   0.943560     0.876791      0.007687      0.002802   \n",
       "\n",
       "       ShapeFactor3  ShapeFactor4         y  \n",
       "0          0.469994      0.998595     HOROZ  \n",
       "1          0.803510      0.997370     SEKER  \n",
       "2          0.700453      0.997737  DERMASON  \n",
       "3          0.685142      0.999250  DERMASON  \n",
       "4          0.684755      0.996507      SIRA  \n",
       "...             ...           ...       ...  \n",
       "10829      0.768513      0.997708     SEKER  \n",
       "10830      0.667517      0.997646  DERMASON  \n",
       "10831      0.553610      0.994412      CALI  \n",
       "10832      0.640255      0.994793      SIRA  \n",
       "10833      0.768762      0.999317  DERMASON  \n",
       "\n",
       "[10834 rows x 18 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train_dry.csv\")\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DryBeanDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data.iloc[:, -1] = self.label_encoder.fit_transform(self.data.iloc[:, -1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.data.iloc[idx, :-1].values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.data.iloc[idx, -1], dtype=torch.long)  # Assuming targets are integers representing classes\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "input_size = 16\n",
    "output_size = 7\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bean_dataset = DryBeanDataset('Dry_Bean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_indices, test_indices = train_test_split(range(len(bean_dataset)), test_size=0.2, random_state=42)\n",
    "\n",
    "train_loader = DataLoader(bean_dataset, batch_size=batch_size, sampler=train_indices)\n",
    "test_loader = DataLoader(bean_dataset, batch_size=batch_size, sampler=test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TwoLayerNet(input_dim, hidden_size, num_classes)\n",
    "\n",
    "X = # torch.randn(100, input_dim)  \n",
    "y = # torch.randint(0, num_classes, (100,))  \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "num_epochs = 500  \n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(X)\n",
    "\n",
    "    loss = criterion(outputs, y)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DryBeanDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "        # Encode target column\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.data['Class'] = self.label_encoder.fit_transform(self.data['Class'])\n",
    "\n",
    "        # Standardize features\n",
    "        self.scaler = StandardScaler()\n",
    "        self.data.iloc[:, :-1] = self.scaler.fit_transform(self.data.iloc[:, :-1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        features = torch.tensor(self.data.iloc[idx, :-1], dtype=torch.float32)\n",
    "        target = torch.tensor(self.data.iloc[idx, -1], dtype=torch.long)\n",
    "        return features, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_classes):\n",
    "        super(TwoLayerNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.lin1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.lin2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 16  # Number of features\n",
    "hidden_size = 64\n",
    "num_classes = 7  # Number of unique target classes\n",
    "model = TwoLayerNet(input_dim, hidden_size, num_classes)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DryBeanDataset('Dry_Bean.csv')\n",
    "train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2965\n",
      "Epoch [2/10], Loss: 1.0962\n",
      "Epoch [3/10], Loss: 0.6332\n",
      "Epoch [4/10], Loss: 0.8547\n",
      "Epoch [5/10], Loss: 0.5511\n",
      "Epoch [6/10], Loss: 0.5180\n",
      "Epoch [7/10], Loss: 0.4838\n",
      "Epoch [8/10], Loss: 0.3119\n",
      "Epoch [9/10], Loss: 0.2670\n",
      "Epoch [10/10], Loss: 0.1749\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
